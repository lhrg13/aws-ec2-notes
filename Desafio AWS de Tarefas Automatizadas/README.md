# Desafio DIO: Automa√ß√£o S3 e Lambda com LocalStack
Este reposit√≥rio documenta a implementa√ß√£o de uma automa√ß√£o *serverless* com S3 e Lambda, como parte do desafio da DIO. O projeto utiliza o **LocalStack** para simular a infraestrutura AWS localmente, permitindo testes r√°pidos e sem custo.

---

### üö© Objetivo do Projeto
Praticar o uso combinado do Amazon S3 e AWS Lambda para criar um fluxo de trabalho orientado a eventos.

* Escrever uma fun√ß√£o Lambda em Python para organizar arquivos.
* Criar um bucket S3 para armazenamento.
* Configurar um trigger (gatilho) no S3 para acionar a Lambda em novos uploads.
* Implementar a l√≥gica da Lambda para mover arquivos para pastas espec√≠ficas.
* Testar a automa√ß√£o fazendo upload de arquivos.
* Verificar o resultado (arquivos movidos).
* Utilizar o LocalStack para simular os servi√ßos AWS localmente.

---

### Amazon S3 (Simple Storage Service)
O Amazon S3 √© um servi√ßo de armazenamento de objetos em nuvem. Neste projeto, foi usado para armazenar os arquivos. Configurei o S3 para acionar a Lambda automaticamente sempre que um novo arquivo fosse enviado.

### AWS Lambda
O AWS Lambda √© um servi√ßo de computa√ß√£o *serverless* que executa c√≥digo em resposta a eventos, sem a necessidade de gerenciar servidores. 
Foi usada para executar o c√≥digo Python. Assim que era acionada pelo S3, a Lambda analisava a extens√£o do arquivo (como .png ou .txt) e movia o arquivo para a pasta correta (como imagens/ ou documentos/).

---

## üìí Conceitos Relacionados

* **LocalStack:** A ferramenta essencial que me permitiu simular o S3 e o Lambda na minha m√°quina (`localhost:4566`).
* **Triggers (Gatilhos):** A configura√ß√£o que "conecta" o S3 √† Lambda, dizendo quando ela deve ser acionada.
* **Arquitetura Orientada a Eventos (EDA):** O padr√£o que usamos. Os servi√ßos n√£o se chamam diretamente, eles apenas reagem a eventos (como um upload de arquivo).
* **IAM Role (Fict√≠cia):** Um ARN "dummy" (...:role/lambda-role) usado no LocalStack para simular as permiss√µes de seguran√ßa que a AWS real exigiria.

---

## Processo de Implementa√ß√£o e Verifica√ß√£o

O processo seguiu os seguintes passos no terminal (PowerShell) com o LocalStack em execu√ß√£o:
1.  **Cria√ß√£o (S3):** Cria√ß√£o do *bucket* "meu-bucket-organizador" via AWS CLI.
2.  **Cria√ß√£o (Lambda):** ECria√ß√£o da fun√ß√£o "OrganizadorDeArquivos" a partir do pacote .zip.
3.  **Permiss√£o:** Execu√ß√£o do "aws lambda add-permission" para permitir que o S3 invoque a Lambda.
4.  **Gatilho (Trigger):** Aplica√ß√£o da notifica√ß√£o (put-bucket-notification-configuration) no bucket S3 para conecta-lo √† fun√ß√£o.
5.  **Teste (Upload):** Envio de arquivos de teste (como relatorio.txt e foto.png) para a raiz do bucket.
6.  **Resultado (S3):** Verifica√ß√£o com aws s3 ls --recursive, que confirmou os arquivos movidos para suas pastas de destino (ex: documentos/).
7.  **Logs (Docker):** Inspe√ß√£o dos logs (docker logs localstack-main) para confirmar as chamadas de API (CopyObject, DeleteObject) executadas pela Lambda.

---

## üìå Aprendizados

* Para evitar um loop, eu adicionei uma verifica√ß√£o. A Lambda ignora arquivos que j√° est√£o na pasta, assim ela n√£o √© acionada de novo pelo seu pr√≥prio movimento.
* "Mover" no S3 n√£o √© um comando √∫nico. A Lambda precisou, na verdade, Copiar o arquivo para o novo local e, em seguida, Apagar o arquivo original.
* O LocalStack tornou tudo mais r√°pido. Ele permitiu testar o fluxo sem precisar configurar permiss√µes (IAM) complexas.
* O evento do S3 √© completo. Ele j√° informa √† Lambda qual arquivo foi enviado e onde ele est√°, ent√£o o c√≥digo pode focar apenas em mov√™-lo.
---

## üìÇ Arquivos do Reposit√≥rio

* **README.md**: Esta documenta√ß√£o.
* **/organizador.py**: O c√≥digo-fonte Python da fun√ß√£o Lambda.
* **/notification.json**: Arquivo de configura√ß√£o do gatilho do S3.
* **/images/**: Capturas de tela do processo (cria√ß√£o, upload, resultado e logs).
